{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2083a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#models\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, Ridge\n",
    "\n",
    "#model validation and preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split, RepeatedKFold\n",
    "#from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, PolynomialFeatures\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "solar = pd.read_csv('rhessi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b02d4907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\1804467434.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  M2.fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Creates intensity target attribute through avg of energy.kev * duration.s\n",
    "- takes a dataframe and returns dataframe with added 'intensity' column\n",
    "'''\n",
    "def addIntensity(data):\n",
    "    avg_energy = (data['energy.kev.i'] + data['energy.kev.f'])/2\n",
    "    data['intensity'] = avg_energy * data['duration.s']\n",
    "    return data\n",
    "\n",
    "#method 1's:\n",
    "\n",
    "M1 = XGBRegressor(learning_rate= 0.248, max_depth= 10, n_estimators= 546)\n",
    "\n",
    "y = solar[[\"total.counts\"]]\n",
    "X = solar[['duration.s', 'peak.c/s', 'x.pos.asec',\n",
    "           'y.pos.asec', 'radial', 'energy.kev.i',\n",
    "           'energy.kev.f', 'day','month','year','active.region.ar']]\n",
    "\n",
    "M1.fit(X, y)\n",
    "\n",
    "#method 2's:\n",
    "solar = addIntensity(solar)\n",
    "\n",
    "M2 = RandomForestRegressor()\n",
    "\n",
    "y = solar[[\"intensity\"]]\n",
    "X = solar[['day','month','year','active.region.ar', 'peak.c/s', 'total.counts', 'x.pos.asec', 'y.pos.asec', 'radial']]\n",
    "\n",
    "M2.fit(X, y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425bd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solar flare data from 2004 and 2005\n",
    "solar_2004_2005 = solar[(solar['year'] == 2004) | (solar['year'] == 2005)]\n",
    "\n",
    "#solar flare data from 2015 and 2016\n",
    "solar_2015_2016 = solar[(solar['year'] == 2015) | (solar['year'] == 2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ba9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Batches Function\n",
    "def make_batches(data, start_year, end_year):\n",
    "    batches = []\n",
    "    for start_month in range(1, 12, 2):\n",
    "        batch = data[\n",
    "            (data['year'] == start_year) & (data['month'].between(start_month, start_month + 3))]\n",
    "        if len(batches) == 5:\n",
    "            batch = data[\n",
    "                ((data['year'] == start_year) & data['month'].between(start_month, start_month + 3)) |\n",
    "                ((data['year'] == end_year) & data['month'].between(1, 2))\n",
    "            ]\n",
    "        batches.append(batch)\n",
    "\n",
    "    for start_month in range(1, 12, 2):\n",
    "        batch = data[\n",
    "            (data['year'] == end_year) & data['month'].between(start_month, start_month + 3)]\n",
    "        if len(batches) <= 10:\n",
    "            batches.append(batch)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e4f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches2004_2005 = make_batches(solar_2004_2005, 2004, 2005)\n",
    "batches2015_2016 = make_batches(solar_2015_2016, 2015, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e24085df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.750600e+04\n",
       "mean     7.418507e+03\n",
       "std      3.129340e+04\n",
       "min      7.200000e+01\n",
       "25%      1.980000e+03\n",
       "50%      3.528000e+03\n",
       "75%      6.882000e+03\n",
       "max      2.200000e+06\n",
       "Name: intensity, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moreover, compute basic statistics (e.g. various counts and averages) for Set 1 and Set 2 and compare those. \n",
    "\n",
    "solar_2004_2005['intensity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7af33eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.077900e+04\n",
       "mean     9.760980e+03\n",
       "std      3.012329e+04\n",
       "min      7.200000e+01\n",
       "25%      2.088000e+03\n",
       "50%      3.816000e+03\n",
       "75%      7.755000e+03\n",
       "max      1.337600e+06\n",
       "Name: intensity, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solar_2015_2016['intensity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1d33d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4006077368.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch0_method1_2004_2005['intensity_pred'] = batch0_method1_y_pred_2004_2005\n",
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4006077368.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch0_method2_2004_2005['intensity_pred'] = batch0_method2_y_pred_2004_2005\n",
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4006077368.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch10_method1_2004_2005['intensity_pred'] = batch10_method1_y_pred_2004_2005\n",
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4006077368.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch10_method2_2004_2005['intensity_pred'] = batch10_method2_y_pred_2004_2005\n"
     ]
    }
   ],
   "source": [
    "# Batches 0 and 10 for the year 2004-2005\n",
    "# Naming convention should follow: batchN_methodN_2004_2005\n",
    "# batch0 1+2+3+4 (also known as batch 1)\n",
    "batch0_method1_2004_2005 = batches2004_2005[0][['duration.s', 'peak.c/s', 'x.pos.asec',\n",
    "                                'y.pos.asec', 'radial', 'energy.kev.i',\n",
    "                                'energy.kev.f', 'day','month','year','active.region.ar']]\n",
    "\n",
    "batch0_method2_2004_2005 = batches2004_2005[0][['day','month','year','active.region.ar', 'peak.c/s',\n",
    "                            'total.counts', 'x.pos.asec', 'y.pos.asec', 'radial']]\n",
    "\n",
    "# batch10 21+22+23+24 (also known as batch 11)\n",
    "batch10_method1_2004_2005 = batches2004_2005[10][['duration.s', 'peak.c/s', 'x.pos.asec',\n",
    "                                'y.pos.asec', 'radial', 'energy.kev.i',\n",
    "                                'energy.kev.f', 'day','month','year','active.region.ar']]\n",
    "\n",
    "batch10_method2_2004_2005 = batches2004_2005[10][['day','month','year','active.region.ar', 'peak.c/s',\n",
    "                            'total.counts', 'x.pos.asec', 'y.pos.asec', 'radial']]\n",
    "\n",
    "# Batch 0 Method 1 2004_2005\n",
    "batch0_method1_y_pred_2004_2005 = M1.predict(batch0_method1_2004_2005)\n",
    "batch0_method1_2004_2005['intensity_pred'] = batch0_method1_y_pred_2004_2005\n",
    "\n",
    "# Batch 0 Method 2 2004_2005\n",
    "batch0_method2_y_pred_2004_2005 = M2.predict(batch0_method2_2004_2005)\n",
    "batch0_method2_2004_2005['intensity_pred'] = batch0_method2_y_pred_2004_2005\n",
    "\n",
    "# Batch 10 Method 1 2004_2005\n",
    "batch10_method1_y_pred_2004_2005 = M1.predict(batch10_method1_2004_2005)\n",
    "batch10_method1_2004_2005['intensity_pred'] = batch10_method1_y_pred_2004_2005\n",
    "\n",
    "# Batch 10 Method 2 2004_2005\n",
    "batch10_method2_y_pred_2004_2005 = M2.predict(batch10_method2_2004_2005)\n",
    "batch10_method2_2004_2005['intensity_pred'] = batch10_method2_y_pred_2004_2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d2202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4072231292.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch0_method1_2015_2016['intensity_pred'] = batch0_method1_y_pred_2015_2016\n",
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4072231292.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch0_method2_2015_2016['intensity_pred'] = batch0_method2_y_pred_2015_2016\n",
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4072231292.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch10_method1_2015_2016['intensity_pred'] = batch10_method1_y_pred_2015_2016\n",
      "C:\\Users\\Joseph\\AppData\\Local\\Temp\\ipykernel_8604\\4072231292.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  batch10_method2_2015_2016['intensity_pred'] = batch10_method2_y_pred_2015_2016\n"
     ]
    }
   ],
   "source": [
    "# Batches 0 and 10 for the year 2015-2016\n",
    "# batch0\n",
    "batch0_method1_2015_2016 = batches2015_2016[0][['duration.s', 'peak.c/s', 'x.pos.asec',\n",
    "                                'y.pos.asec', 'radial', 'energy.kev.i',\n",
    "                                'energy.kev.f', 'day','month','year','active.region.ar']]\n",
    "\n",
    "batch0_method2_2015_2016 = batches2015_2016[0][['day','month','year','active.region.ar', 'peak.c/s',\n",
    "                            'total.counts', 'x.pos.asec', 'y.pos.asec', 'radial']]\n",
    "\n",
    "# batch10\n",
    "batch10_method1_2015_2016 = batches2015_2016[10][['duration.s', 'peak.c/s', 'x.pos.asec',\n",
    "                                'y.pos.asec', 'radial', 'energy.kev.i',\n",
    "                                'energy.kev.f', 'day','month','year','active.region.ar']]\n",
    "\n",
    "batch10_method2_2015_2016 = batches2015_2016[10][['day','month','year','active.region.ar', 'peak.c/s',\n",
    "                            'total.counts', 'x.pos.asec', 'y.pos.asec', 'radial']]\n",
    "\n",
    "# Batch 0 Method 1 2015_2016\n",
    "batch0_method1_y_pred_2015_2016 = M1.predict(batch0_method1_2015_2016)\n",
    "batch0_method1_2015_2016['intensity_pred'] = batch0_method1_y_pred_2015_2016\n",
    "\n",
    "# Batch 0 Method 2 2015_2016\n",
    "batch0_method2_y_pred_2015_2016= M2.predict(batch0_method2_2015_2016)\n",
    "batch0_method2_2015_2016['intensity_pred'] = batch0_method2_y_pred_2015_2016\n",
    "\n",
    "# Batch 10 Method 1 2015_2016\n",
    "batch10_method1_y_pred_2015_2016 = M1.predict(batch10_method1_2015_2016)\n",
    "batch10_method1_2015_2016['intensity_pred'] = batch10_method1_y_pred_2015_2016\n",
    "\n",
    "# Batch 10 Method 2 2015_2016\n",
    "batch10_method2_y_pred_2015_2016 = M2.predict(batch10_method2_2015_2016)\n",
    "batch10_method2_2015_2016['intensity_pred'] = batch10_method2_y_pred_2015_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376476c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155390b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cannot use features used to create 'intensity' solar[['energy.kev.i', 'energy.kev.f', 'duration.s']]\n",
    "#Method 2: first creating the intensity variable (target_variable)\n",
    "\n",
    "'''\n",
    "currently creates intensity target parameter through avg of energy.kev * duration.s\n",
    "'''\n",
    "def addIntensity(data):\n",
    "    avg_energy = (data['energy.kev.i'] + data['energy.kev.f'])/2\n",
    "    data['intensity'] = avg_energy * data['duration.s']\n",
    "    return data\n",
    "\n",
    "\n",
    "solar_2 = addIntensity(solar)\n",
    "\"\"\"\n",
    "#method 1's:\n",
    "y = solar_2[[\"total.counts\"]]\n",
    "X = solar_2[['duration.s', 'peak.c/s', 'x.pos.asec', \n",
    "           'y.pos.asec', 'radial', 'energy.kev.i', \n",
    "           'energy.kev.f', 'day','month','year','active.region.ar']]\n",
    "\"\"\"\n",
    "\n",
    "#method 2's:\n",
    "y = solar_2[[\"intensity\"]]\n",
    "X = solar_2[['day','month','year','active.region.ar', 'peak.c/s', 'total.counts', 'x.pos.asec', 'y.pos.asec', 'radial']]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size =0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56a8e6",
   "metadata": {},
   "source": [
    "# Results (M1):\n",
    "\n",
    "XGBRegressor(learning_rate= 0.248, max_depth= 10, n_estimators= 546)\n",
    "- Mean MAE: 138029.805 (17625.737)\n",
    "\n",
    "RandomForestRegressor()\n",
    "- Mean MAE: 139686.422 (17620.332)\n",
    "\n",
    "Pipeline( [('poly' , PolynomialFeatures(degree = 2, include_bias = False, interaction_only = False)),                  ('lin_r', LinearRegression()) ])\n",
    "- Mean MAE: 282348.380 (253154.974)\n",
    "\n",
    "SVR()\n",
    "- Mean MAE: 347294.496 (35389.136)\n",
    "\n",
    "slr = Pipeline([('scaler', RobustScaler()),('svr',SVR(max_iter = 100000))])\n",
    "- Mean MAE: 347933.764 (35413.271)\n",
    "\n",
    "Pipeline([('scaler', RobustScaler()), ('linear', LinearRegression(fit_intercept = False))])\n",
    "- Mean MAE: 356138.574 (17816.858)\n",
    "\n",
    "Pipeline(steps=[('robust', RobustScaler()),\n",
    "                ('ridge',\n",
    "                 Ridge(alpha=9.391053524878311, tol=0.000841380674450156))])\n",
    "- Mean MAE: 402379.564 (16763.954)\n",
    "\n",
    "LinearRegression()\n",
    "- Mean MAE: 402429.099 (16769.803)\n",
    "\n",
    "ridge = Ridge(alpha=8.501992226787863, tol=0.0007708353644612364)\n",
    "- Mean MAE: 402429.088 (16769.796)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c275a",
   "metadata": {},
   "source": [
    "# Results (M2):\n",
    "\n",
    "XGBRegressor(learning_rate= 0.0597, max_depth= 4, n_estimators= 229)\n",
    "- Mean MAE: 3971.186 (170.351)\n",
    "\n",
    "RandomForestRegressor()\n",
    "- Mean MAE: 4162.393 (193.812)\n",
    "\n",
    "Pipeline([('poly' , PolynomialFeatures(degree = 3, include_bias = False, interaction_only = True)), ('lin_r', LinearRegression())])\n",
    "- Mean MAE: 3157.079 (102.188)\n",
    "\n",
    "LinearRegression()\n",
    "- Mean MAE: 3262.677 (100.384)\n",
    "\n",
    "Ridge(alpha=9.739625063533492, tol=7.842778538788441e-05)\n",
    "- Mean MAE: 3262.677 (100.384)\n",
    "\n",
    "Pipeline(steps=[('standard', StandardScaler()),\n",
    "                ('ridge',\n",
    "                 Ridge(alpha=1.157737190630861, tol=0.0008946473923448764))])\n",
    "- Mean MAE: 3262.680 (100.384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f3c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4849.42691497 5545.17238524 4655.90128572 5031.38925448 5280.22936411\n",
      " 4877.37605448 4721.62592599 5005.0724105  5084.90464842 5589.01963599\n",
      " 5091.56428457 4995.27169878 4906.52154967 5158.38121743 5374.0170681\n",
      " 5170.12071312 4636.55675461 4740.67858758 5074.1103134  4890.20900364\n",
      " 4755.47401167 5015.79602125 5321.70589645 4738.58029261 5351.96264504\n",
      " 4900.01148511 5053.72903121 5091.83810483 4998.89795772 4973.79452312]\n",
      "Mean MAE: 5029.311 (241.139)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We make the mean_absolute_error negative because scikit-learn assumes a higher number is better for scoring.\n",
    "That's why we take the absolute value of our score at the end.\n",
    "A lower MAE is better! \n",
    "'''\n",
    "def cv(model):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X_train, y_train, \n",
    "                             scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    #for cross_val being used:\n",
    "    scores = np.absolute(scores)\n",
    "    print(scores)\n",
    "    print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The different search algo's benefits:\n",
    "\n",
    "RandomizedSearchCV\n",
    "    + less computationally expensive than GridSearchCV\n",
    "    - not as robust(?) as GridSearchCV\n",
    "\n",
    "GridSearchCV\n",
    "    - computationally expensive\n",
    "    - does not do well with large param list\n",
    "    \n",
    "HalvingGridSearchCV\n",
    "    + less computationally expensive\n",
    "    + does some battle royal stuff to narrow search pool\n",
    "    - for complex models and param lists\n",
    "\"\"\"\n",
    "def grid(model, params):\n",
    "    grid_search = RandomizedSearchCV(model, params, cv=5, scoring='neg_mean_absolute_error',\n",
    "                                     verbose=10, n_jobs=10, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"\\n The best estimator:\\n\", grid_search.best_estimator_)\n",
    "    print(\"\\n The best score:\\n\", grid_search.best_score_)\n",
    "    print(\"\\n The best parameters:\\n\", grid_search.best_params_)\n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "XGBoost is known as one of the strongest models, need to become like thanos and harness this stone\n",
    "\n",
    "XGBoost Notes: \n",
    "- when we changed the scoring within our gridsearch to 'neg_mean_absolute_error' the hyperparameters performed better\n",
    "\n",
    "RandomForest Notes:\n",
    "- base model performed just as well as optimized XGBoost, ffs\n",
    "- RandomForest after gridSearch performed worse than base model\n",
    "\n",
    "polynomial regression:\n",
    "- takes up a lot of memory (failed some fits during hyperparameter tuning bc of this)\n",
    "- need to kernel trick features (feature space mapping)\n",
    "\n",
    "\n",
    "scaling vs. centering\n",
    "- scaling is when we want to transform our values to a specific range (everything's got similar magnitudes)\n",
    "- centering is shifting values so they have a mean of 0 (subtract mean of feature from every value)\n",
    "\n",
    "linear Regression:\n",
    "- dogshit without scaling (probably)\n",
    "- linear Regression also performed essentially the same with and without scaling, this brought to my attention \n",
    "the fact that scikit-learn has it's own internal normalization step during training (go figure)\n",
    "- for M1, when fit_intercept = False, standardScaler pipeline shit the bed, but RobustScaler did better than \n",
    "base linear Regression & base Robust linear Regression (interesting, wonder if has to do with the centering done by\n",
    "RobustScaler & it's ability to handle data with outliers)\n",
    "\n",
    "ridge Regression:\n",
    "- ridge regression is less sensitive to magnitude (both types of scaled & unscaled data got same result)\n",
    "- performed better on M1 than M2, standardScaler performed better than RobustScaler on M1 as well\n",
    "\n",
    "\n",
    "RobustScaler vs StandardScaler\n",
    "- Robust uses median & IQR\n",
    "- Standard uses mean & standard deviation\n",
    "- Robust is good for outlier heavy dataset, Standard is not\n",
    "\n",
    "Support Vector Machine:\n",
    "- So goddamn computationally expensive, it's wild\n",
    "- Oddly enough, using RobustScaler on the data resulted in a worse MAE\n",
    "\n",
    "Thoughts on results:\n",
    "- The dataset seems to be complex (go figure dumbass), the performance of the linear model and it's variations\n",
    "does not compare to the tree algorithms\n",
    "\"\"\"\n",
    "#xg= XGBRegressor(learning_rate= 0.248, max_depth= 10, n_estimators= 546)\n",
    "#Mean MAE: 138029.805 (17625.737)\n",
    "\n",
    "\n",
    "xgr = Pipeline([('poly' , PolynomialFeatures(degree = 3, include_bias = False, interaction_only = True)), ('lin_r', LinearRegression())])\n",
    "\n",
    "'''\n",
    "example of the params_list for the XGBRegressor() model\n",
    "used for RandomizedSearchCV\n",
    "'''\n",
    "xg_params = {\n",
    "    'n_estimators' : randint(100,1201),\n",
    "    'max_depth' : randint(1,11),\n",
    "    'learning_rate' : uniform(0.001, 0.3)\n",
    "}\n",
    "\n",
    "#Next task: \n",
    "\n",
    "slr = Pipeline([('scaler', RobustScaler()),('svr',SVR(max_iter = 100000))])\n",
    "#main:\n",
    "\n",
    "cv(xgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c64adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1cd08",
   "metadata": {},
   "source": [
    "### Everything after this point is just experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9969259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeRegressor Pipelines\n",
    "#we are going to score it in different ways \n",
    "treePipe = Pipeline([('regressor', RandomForestRegressor(random_state=0, verbose=3, n_jobs=10))])\n",
    "tree_params = {\n",
    "    'regressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],  # Splitting criterion\n",
    "    'regressor__max_depth': [None, 10, 20, 30, 40],  # Maximum depth of the tree\n",
    "    'regressor__min_samples_leaf': [1, 2, 4], # Minimum samples required at a leaf node\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(treePipe, tree_params,\n",
    "                           cv=5, verbose=10, \n",
    "                           refit=True)\n",
    "\n",
    "#results: friedman_mse, regression max_depth = 40, min_samples leaf=4\n",
    "#results 2.0 = squared error, regressor_max_depth = None, min_samples leaf = 1\n",
    "#things we learned: gridsearchcv needs to handeled with care\n",
    "grid_search.fit(X, np.ravel(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6ac85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_jobs=5, \n",
    "                      verbose=3, criterion='friedman_mse', \n",
    "                      max_depth =40, min_samples_leaf=4)\n",
    "#with random_state = 0, score is 0.95\n",
    "#without setting random_state obtained a result similar \n",
    "scores = cross_val_score(forest, X, y, n_jobs = 1)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f4a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svr_params = {\n",
    "    'svr__C': [0.1, 1, 10, 100],\n",
    "    'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'svr__gamma': [0.01, 0.1, 1, 'scale', 'auto'],\n",
    "}\n",
    "svr_pipe = Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "#Notes:\n",
    "#without scaled data, score's were very large or non-existent, going to experiment now with max_iter and scaled data\n",
    "grid_search = RandomizedSearchCV(svr_pipe, svr_params, cv=5,\n",
    " n_iter = 5,verbose=10,\n",
    " n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X, np.ravel(y))\n",
    "print(\"\\n The best estimator:\\n\", grid_search.best_estimator_)\n",
    "print(\"\\n The best score:\\n\", grid_search.best_score_)\n",
    "print(\"\\n The best parameters:\\n\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GradientBoostingRegressor is not looking good for method 2, we are going to try it on method 1 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = solar_2[[\"intensity\"]]\n",
    "X = solar_2[['day','month','year','active.region.ar', 'peak.c/s', 'total.counts', 'x.pos.asec', 'y.pos.asec', 'radial']]\n",
    "gb = GradientBoostingRegressor(random_state=2)\n",
    "\n",
    "initial_params = {}\n",
    "gs = GridSearchCV(estimator = gb, param_grid = initial_params,n_jobs=10, verbose = 10)\n",
    "gs.fit(X, np.ravel(y))\n",
    "print(\"\\n The best estimator:\\n\", gs.best_estimator_)\n",
    "print(\"\\n The best score:\\n\", gs.best_score_)\n",
    "print(\"\\n The best parameters:\\n\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428efb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = solar[[\"total.counts\"]]\n",
    "X = solar[['duration.s', 'peak.c/s', 'x.pos.asec', 'y.pos.asec', 'radial', 'energy.kev.i', 'energy.kev.f']]\n",
    "#gb = GradientBoostingRegressor(random_state=2, learning_rate = 0.2, n_estimators=40, min_samples_split = 10)\n",
    "gb = XGBRegressor(random_state=2)\n",
    "param_grid = {'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "gs = GridSearchCV(estimator = gb, param_grid = initial_params,\n",
    "                  n_jobs=10, verbose = 10)\n",
    "gs.fit(X, y)\n",
    "print(\"\\n The best estimator:\\n\", gs.best_estimator_)\n",
    "print(\"\\n The best score:\\n\", gs.best_score_)\n",
    "print(\"\\n The best parameters:\\n\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {'gradient__min_samples_split': [0.01, 0.1, 1, 'scale', 'auto'], \n",
    "              'gradient_warm_start' : [False, True],\n",
    "              'gradient_learning_rate' : [0.05, 0.1, 0.15, 0.2]}\n",
    "#Notes:\n",
    "#svr's were not able to capture the relationship\n",
    "grid_search = RandomizedSearchCV(gb_pipe, gb_params, cv=5,\n",
    " n_iter = 5,verbose=10, random_state=42,\n",
    " n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X, np.ravel(y))\n",
    "print(\"\\n The best estimator:\\n\", grid_search.best_estimator_)\n",
    "print(\"\\n The best score:\\n\", grid_search.best_score_)\n",
    "print(\"\\n The best parameters:\\n\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f317464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = RandomizedSearchCV(svr_pipe, svr_params, cv=5,\n",
    " n_iter = 5,verbose=10, random_state=42,\n",
    " n_jobs=10, return_train_score=True)\n",
    "grid_search.fit(X, np.ravel(y))\n",
    "print(\"\\n The best estimator:\\n\", grid_search.best_estimator_)\n",
    "print(\"\\n The best score:\\n\", grid_search.best_score_)\n",
    "print(\"\\n The best parameters:\\n\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b313d69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration.s</th>\n",
       "      <th>peak.c/s</th>\n",
       "      <th>total.counts</th>\n",
       "      <th>x.pos.asec</th>\n",
       "      <th>y.pos.asec</th>\n",
       "      <th>radial</th>\n",
       "      <th>active.region.ar</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>energy.kev.i</th>\n",
       "      <th>energy.kev.f</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>1.081820e+05</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>108182.000000</td>\n",
       "      <td>1.081820e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>494.275647</td>\n",
       "      <td>210.735363</td>\n",
       "      <td>3.735130e+05</td>\n",
       "      <td>0.943780</td>\n",
       "      <td>-34.201485</td>\n",
       "      <td>713.441404</td>\n",
       "      <td>1056.193535</td>\n",
       "      <td>2009.092927</td>\n",
       "      <td>6.672080</td>\n",
       "      <td>15.588203</td>\n",
       "      <td>7.930469</td>\n",
       "      <td>16.418323</td>\n",
       "      <td>4.718839e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>431.102410</td>\n",
       "      <td>852.139223</td>\n",
       "      <td>3.114586e+06</td>\n",
       "      <td>708.603208</td>\n",
       "      <td>264.625164</td>\n",
       "      <td>253.929243</td>\n",
       "      <td>1371.022947</td>\n",
       "      <td>4.839022</td>\n",
       "      <td>3.454303</td>\n",
       "      <td>8.794025</td>\n",
       "      <td>22.561547</td>\n",
       "      <td>70.015105</td>\n",
       "      <td>1.271962e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>-1007.000000</td>\n",
       "      <td>-998.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>212.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2.263200e+04</td>\n",
       "      <td>-731.000000</td>\n",
       "      <td>-254.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.320000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>368.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.695200e+04</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-101.000000</td>\n",
       "      <td>785.000000</td>\n",
       "      <td>758.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.376000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>628.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>1.722240e+05</td>\n",
       "      <td>736.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.632000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4444.000000</td>\n",
       "      <td>113156.000000</td>\n",
       "      <td>4.355501e+08</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>1.200000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration.s       peak.c/s  total.counts     x.pos.asec  \\\n",
       "count  108182.000000  108182.000000  1.081820e+05  108182.000000   \n",
       "mean      494.275647     210.735363  3.735130e+05       0.943780   \n",
       "std       431.102410     852.139223  3.114586e+06     708.603208   \n",
       "min         8.000000       0.000000  8.000000e+00   -1007.000000   \n",
       "25%       212.000000      28.000000  2.263200e+04    -731.000000   \n",
       "50%       368.000000      52.000000  5.695200e+04      -5.000000   \n",
       "75%       628.000000     136.000000  1.722240e+05     736.000000   \n",
       "max      4444.000000  113156.000000  4.355501e+08    1005.000000   \n",
       "\n",
       "          y.pos.asec         radial  active.region.ar           year  \\\n",
       "count  108182.000000  108182.000000     108182.000000  108182.000000   \n",
       "mean      -34.201485     713.441404       1056.193535    2009.092927   \n",
       "std       264.625164     253.929243       1371.022947       4.839022   \n",
       "min      -998.000000       0.000000          0.000000    2002.000000   \n",
       "25%      -254.000000     519.000000         50.000000    2004.000000   \n",
       "50%      -101.000000     785.000000        758.000000    2011.000000   \n",
       "75%       206.000000     948.000000       1620.000000    2013.000000   \n",
       "max      1012.000000    1015.000000       9999.000000    2018.000000   \n",
       "\n",
       "               month            day   energy.kev.i   energy.kev.f  \\\n",
       "count  108182.000000  108182.000000  108182.000000  108182.000000   \n",
       "mean        6.672080      15.588203       7.930469      16.418323   \n",
       "std         3.454303       8.794025      22.561547      70.015105   \n",
       "min         1.000000       1.000000       6.000000      12.000000   \n",
       "25%         4.000000       8.000000       6.000000      12.000000   \n",
       "50%         7.000000      15.000000       6.000000      12.000000   \n",
       "75%        10.000000      23.000000       6.000000      12.000000   \n",
       "max        12.000000      31.000000    7000.000000   20000.000000   \n",
       "\n",
       "          intensity  \n",
       "count  1.081820e+05  \n",
       "mean   4.718839e+03  \n",
       "std    1.271962e+04  \n",
       "min    4.800000e+01  \n",
       "25%    1.320000e+03  \n",
       "50%    2.376000e+03  \n",
       "75%    4.632000e+03  \n",
       "max    1.200000e+06  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solar_2.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
